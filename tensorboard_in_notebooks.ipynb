{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TsHV-7cpVkyK"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "form",
    "id": "atWM-s8yVnfX"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TB0wBWfcVqHz"
   },
   "source": [
    "# Using TensorBoard in Notebooks\n",
    "\n",
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/tensorboard/blob/master/docs/tensorboard_in_notebooks.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/tensorboard/blob/master/docs/tensorboard_in_notebooks.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/tensorboard/docs/tensorboard_in_notebooks.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "elH58gbhWAmn"
   },
   "source": [
    "TensorBoard can be used directly within notebook experiences such as [Colab](https://colab.research.google.com/) and [Jupyter](https://jupyter.org/). This can be helpful for sharing results, integrating TensorBoard into existing workflows, and using TensorBoard without installing anything locally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VszJNloY3ZU3"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E6QhA_dp3eRq"
   },
   "source": [
    "Start by installing TF 2.0 and loading the TensorBoard notebook extension:\n",
    "\n",
    "**For Jupyter users:** If you’ve installed Jupyter and TensorBoard into\n",
    "the same virtualenv, then you should be good to go. If you’re using a\n",
    "more complicated setup, like a global Jupyter installation and kernels\n",
    "for different Conda/virtualenv environments, then you must ensure that\n",
    "the `tensorboard` binary is on your `PATH` inside the Jupyter notebook\n",
    "context. One way to do this is to modify the `kernel_spec` to prepend\n",
    "the environment’s `bin` directory to `PATH`, [as described here][1].\n",
    "\n",
    "[1]: https://github.com/ipython/ipykernel/issues/395#issuecomment-479787997\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9w7Baxc8aCtJ"
   },
   "source": [
    "**For Docker users:** In case you are running a [Docker](https://docs.docker.com/install/) image of [Jupyter Notebook server using TensorFlow's nightly](https://www.tensorflow.org/install/docker#examples_using_cpu-only_images), it is necessary to expose not only the notebook's port, but the TensorBoard's port. Thus, run the container with the following command:\n",
    "\n",
    "```\n",
    "docker run -it -p 8888:8888 -p 6006:6006 \\\n",
    "tensorflow/tensorflow:nightly-py3-jupyter \n",
    "```\n",
    "\n",
    "where the `-p 6006` is the default port of TensorBoard. This will allocate a port for you to run one TensorBoard instance. To have concurrent instances, it is necessary to allocate more ports. Also, pass `--bind_all` to `%tensorboard` to expose the port outside the container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "8p3Tbx8cWEFA"
   },
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9GtR_cTTkf9G"
   },
   "source": [
    "Import TensorFlow, datetime, and os:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "mVtYvbbIWRkV"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import datetime, os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cu1fbH-S3oAX"
   },
   "source": [
    "## TensorBoard in notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XfCa27_8kov6"
   },
   "source": [
    "Download the [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist) dataset and scale it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "z8b82G7YksOS"
   },
   "outputs": [],
   "source": [
    "# fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "# (x_train, y_train),(x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "from utils.local_datasets import load_data_fashion_mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = load_data_fashion_mnist()\n",
    "\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lBk1BqAZKEKd"
   },
   "source": [
    "Create a very simple model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "OS7qGYiMKGQl"
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "  return tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "  ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RNaPPs5ZKNOV"
   },
   "source": [
    "Train the model using Keras and the TensorBoard callback:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "lpUO9HqUKP6z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   1/1875 [..............................] - ETA: 0s - loss: 2.2599 - accuracy: 0.1562WARNING:tensorflow:From /opt/miniconda3/lib/python3.7/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0016s vs `on_train_batch_end` time: 0.0070s). Check your callbacks.\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4951 - accuracy: 0.8221 - val_loss: 0.4141 - val_accuracy: 0.8552\n",
      "Epoch 2/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3822 - accuracy: 0.8602 - val_loss: 0.4148 - val_accuracy: 0.8468\n",
      "Epoch 3/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3493 - accuracy: 0.8715 - val_loss: 0.3643 - val_accuracy: 0.8673\n",
      "Epoch 4/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3292 - accuracy: 0.8778 - val_loss: 0.3470 - val_accuracy: 0.8747\n",
      "Epoch 5/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3116 - accuracy: 0.8839 - val_loss: 0.3550 - val_accuracy: 0.8741\n",
      "Epoch 6/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2964 - accuracy: 0.8899 - val_loss: 0.3238 - val_accuracy: 0.8808\n",
      "Epoch 7/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2877 - accuracy: 0.8930 - val_loss: 0.3499 - val_accuracy: 0.8770\n",
      "Epoch 8/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2769 - accuracy: 0.8971 - val_loss: 0.3368 - val_accuracy: 0.8800\n",
      "Epoch 9/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2695 - accuracy: 0.8998 - val_loss: 0.3425 - val_accuracy: 0.8812\n",
      "Epoch 10/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2620 - accuracy: 0.9023 - val_loss: 0.3420 - val_accuracy: 0.8868\n",
      "Epoch 11/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2531 - accuracy: 0.9044 - val_loss: 0.3221 - val_accuracy: 0.8861\n",
      "Epoch 12/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2507 - accuracy: 0.9068 - val_loss: 0.3349 - val_accuracy: 0.8827\n",
      "Epoch 13/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2425 - accuracy: 0.9085 - val_loss: 0.3308 - val_accuracy: 0.8866\n",
      "Epoch 14/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2353 - accuracy: 0.9115 - val_loss: 0.3341 - val_accuracy: 0.8874\n",
      "Epoch 15/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2302 - accuracy: 0.9143 - val_loss: 0.3450 - val_accuracy: 0.8820\n",
      "Epoch 16/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2262 - accuracy: 0.9156 - val_loss: 0.3451 - val_accuracy: 0.8849\n",
      "Epoch 17/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2212 - accuracy: 0.9163 - val_loss: 0.3458 - val_accuracy: 0.8900\n",
      "Epoch 18/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2146 - accuracy: 0.9190 - val_loss: 0.3434 - val_accuracy: 0.8878\n",
      "Epoch 19/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2147 - accuracy: 0.9189 - val_loss: 0.3327 - val_accuracy: 0.8920\n",
      "Epoch 20/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2081 - accuracy: 0.9216 - val_loss: 0.3602 - val_accuracy: 0.8873\n",
      "Epoch 21/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2038 - accuracy: 0.9239 - val_loss: 0.3515 - val_accuracy: 0.8911\n",
      "Epoch 22/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2021 - accuracy: 0.9232 - val_loss: 0.3400 - val_accuracy: 0.8978\n",
      "Epoch 23/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1967 - accuracy: 0.9261 - val_loss: 0.3410 - val_accuracy: 0.8923\n",
      "Epoch 24/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1942 - accuracy: 0.9264 - val_loss: 0.3331 - val_accuracy: 0.8958\n",
      "Epoch 25/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1910 - accuracy: 0.9272 - val_loss: 0.3508 - val_accuracy: 0.8880\n",
      "Epoch 26/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1881 - accuracy: 0.9291 - val_loss: 0.3588 - val_accuracy: 0.8940\n",
      "Epoch 27/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1844 - accuracy: 0.9296 - val_loss: 0.3584 - val_accuracy: 0.8922\n",
      "Epoch 28/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1831 - accuracy: 0.9307 - val_loss: 0.3599 - val_accuracy: 0.8890\n",
      "Epoch 29/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1806 - accuracy: 0.9318 - val_loss: 0.3716 - val_accuracy: 0.8920\n",
      "Epoch 30/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1774 - accuracy: 0.9324 - val_loss: 0.3723 - val_accuracy: 0.8928\n",
      "Epoch 31/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1743 - accuracy: 0.9340 - val_loss: 0.3889 - val_accuracy: 0.8899\n",
      "Epoch 32/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1745 - accuracy: 0.9343 - val_loss: 0.3853 - val_accuracy: 0.8930\n",
      "Epoch 33/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1662 - accuracy: 0.9364 - val_loss: 0.3934 - val_accuracy: 0.8908\n",
      "Epoch 34/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1685 - accuracy: 0.9343 - val_loss: 0.3816 - val_accuracy: 0.8939\n",
      "Epoch 35/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1637 - accuracy: 0.9377 - val_loss: 0.4209 - val_accuracy: 0.8879\n",
      "Epoch 36/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1611 - accuracy: 0.9397 - val_loss: 0.3758 - val_accuracy: 0.8959\n",
      "Epoch 37/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1614 - accuracy: 0.9386 - val_loss: 0.4149 - val_accuracy: 0.8937\n",
      "Epoch 38/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1583 - accuracy: 0.9396 - val_loss: 0.3960 - val_accuracy: 0.8909\n",
      "Epoch 39/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1540 - accuracy: 0.9413 - val_loss: 0.4842 - val_accuracy: 0.8693\n",
      "Epoch 40/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1533 - accuracy: 0.9419 - val_loss: 0.4212 - val_accuracy: 0.8904\n",
      "Epoch 41/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1542 - accuracy: 0.9419 - val_loss: 0.4292 - val_accuracy: 0.8936\n",
      "Epoch 42/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1520 - accuracy: 0.9431 - val_loss: 0.4291 - val_accuracy: 0.8904\n",
      "Epoch 43/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1488 - accuracy: 0.9433 - val_loss: 0.4207 - val_accuracy: 0.8903\n",
      "Epoch 44/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1488 - accuracy: 0.9427 - val_loss: 0.4020 - val_accuracy: 0.8940\n",
      "Epoch 45/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1459 - accuracy: 0.9446 - val_loss: 0.4294 - val_accuracy: 0.8975\n",
      "Epoch 46/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1443 - accuracy: 0.9456 - val_loss: 0.4212 - val_accuracy: 0.8955\n",
      "Epoch 47/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1418 - accuracy: 0.9459 - val_loss: 0.4245 - val_accuracy: 0.8959\n",
      "Epoch 48/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1392 - accuracy: 0.9460 - val_loss: 0.4325 - val_accuracy: 0.8915\n",
      "Epoch 49/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1415 - accuracy: 0.9465 - val_loss: 0.4242 - val_accuracy: 0.8954\n",
      "Epoch 50/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1382 - accuracy: 0.9481 - val_loss: 0.4348 - val_accuracy: 0.8960\n",
      "Epoch 51/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1360 - accuracy: 0.9481 - val_loss: 0.4427 - val_accuracy: 0.8969\n",
      "Epoch 52/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1379 - accuracy: 0.9481 - val_loss: 0.4418 - val_accuracy: 0.8942\n",
      "Epoch 53/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1332 - accuracy: 0.9494 - val_loss: 0.4215 - val_accuracy: 0.8993\n",
      "Epoch 54/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1338 - accuracy: 0.9493 - val_loss: 0.4689 - val_accuracy: 0.8936\n",
      "Epoch 55/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1300 - accuracy: 0.9503 - val_loss: 0.4404 - val_accuracy: 0.8985\n",
      "Epoch 56/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1285 - accuracy: 0.9506 - val_loss: 0.4576 - val_accuracy: 0.8960\n",
      "Epoch 57/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1273 - accuracy: 0.9511 - val_loss: 0.5129 - val_accuracy: 0.8857\n",
      "Epoch 58/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1274 - accuracy: 0.9506 - val_loss: 0.4794 - val_accuracy: 0.8970\n",
      "Epoch 59/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1266 - accuracy: 0.9530 - val_loss: 0.4793 - val_accuracy: 0.8969\n",
      "Epoch 60/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1232 - accuracy: 0.9529 - val_loss: 0.4801 - val_accuracy: 0.8910\n",
      "Epoch 61/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1243 - accuracy: 0.9531 - val_loss: 0.4825 - val_accuracy: 0.8985\n",
      "Epoch 62/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1272 - accuracy: 0.9522 - val_loss: 0.4751 - val_accuracy: 0.8953\n",
      "Epoch 63/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1192 - accuracy: 0.9553 - val_loss: 0.4834 - val_accuracy: 0.8988\n",
      "Epoch 64/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1173 - accuracy: 0.9556 - val_loss: 0.5102 - val_accuracy: 0.8982\n",
      "Epoch 65/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1203 - accuracy: 0.9547 - val_loss: 0.4748 - val_accuracy: 0.8955\n",
      "Epoch 66/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1208 - accuracy: 0.9545 - val_loss: 0.5046 - val_accuracy: 0.8973\n",
      "Epoch 67/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1187 - accuracy: 0.9556 - val_loss: 0.4997 - val_accuracy: 0.8920\n",
      "Epoch 68/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1165 - accuracy: 0.9552 - val_loss: 0.5077 - val_accuracy: 0.8939\n",
      "Epoch 69/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1163 - accuracy: 0.9553 - val_loss: 0.5327 - val_accuracy: 0.8901\n",
      "Epoch 70/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1136 - accuracy: 0.9559 - val_loss: 0.5282 - val_accuracy: 0.8958\n",
      "Epoch 71/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1145 - accuracy: 0.9557 - val_loss: 0.4889 - val_accuracy: 0.8976\n",
      "Epoch 72/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1147 - accuracy: 0.9563 - val_loss: 0.5045 - val_accuracy: 0.8984\n",
      "Epoch 73/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1110 - accuracy: 0.9574 - val_loss: 0.5222 - val_accuracy: 0.8915\n",
      "Epoch 74/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1129 - accuracy: 0.9571 - val_loss: 0.5295 - val_accuracy: 0.8978\n",
      "Epoch 75/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1120 - accuracy: 0.9570 - val_loss: 0.5414 - val_accuracy: 0.8920\n",
      "Epoch 76/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1078 - accuracy: 0.9592 - val_loss: 0.5175 - val_accuracy: 0.8954\n",
      "Epoch 77/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1112 - accuracy: 0.9586 - val_loss: 0.5605 - val_accuracy: 0.8939\n",
      "Epoch 78/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1076 - accuracy: 0.9592 - val_loss: 0.5494 - val_accuracy: 0.8961\n",
      "Epoch 79/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1077 - accuracy: 0.9584 - val_loss: 0.5369 - val_accuracy: 0.8978\n",
      "Epoch 80/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1097 - accuracy: 0.9584 - val_loss: 0.5445 - val_accuracy: 0.8937\n",
      "Epoch 81/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1084 - accuracy: 0.9589 - val_loss: 0.5486 - val_accuracy: 0.8936\n",
      "Epoch 82/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1057 - accuracy: 0.9602 - val_loss: 0.5821 - val_accuracy: 0.8994\n",
      "Epoch 83/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1080 - accuracy: 0.9590 - val_loss: 0.5382 - val_accuracy: 0.8956\n",
      "Epoch 84/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1045 - accuracy: 0.9597 - val_loss: 0.5447 - val_accuracy: 0.8940\n",
      "Epoch 85/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1008 - accuracy: 0.9623 - val_loss: 0.5528 - val_accuracy: 0.8976\n",
      "Epoch 86/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1028 - accuracy: 0.9605 - val_loss: 0.5630 - val_accuracy: 0.8962\n",
      "Epoch 87/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1047 - accuracy: 0.9604 - val_loss: 0.5783 - val_accuracy: 0.8901\n",
      "Epoch 88/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1045 - accuracy: 0.9606 - val_loss: 0.5797 - val_accuracy: 0.8962\n",
      "Epoch 89/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0986 - accuracy: 0.9625 - val_loss: 0.5965 - val_accuracy: 0.8973\n",
      "Epoch 90/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1024 - accuracy: 0.9617 - val_loss: 0.5603 - val_accuracy: 0.8966\n",
      "Epoch 91/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1009 - accuracy: 0.9624 - val_loss: 0.6044 - val_accuracy: 0.8949\n",
      "Epoch 92/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1012 - accuracy: 0.9622 - val_loss: 0.5556 - val_accuracy: 0.8982\n",
      "Epoch 93/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0979 - accuracy: 0.9623 - val_loss: 0.6277 - val_accuracy: 0.8964\n",
      "Epoch 94/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0979 - accuracy: 0.9629 - val_loss: 0.5843 - val_accuracy: 0.8942\n",
      "Epoch 95/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0954 - accuracy: 0.9635 - val_loss: 0.6030 - val_accuracy: 0.8964\n",
      "Epoch 96/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0975 - accuracy: 0.9628 - val_loss: 0.5665 - val_accuracy: 0.8986\n",
      "Epoch 97/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0958 - accuracy: 0.9637 - val_loss: 0.5956 - val_accuracy: 0.8974\n",
      "Epoch 98/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0958 - accuracy: 0.9632 - val_loss: 0.6516 - val_accuracy: 0.8933\n",
      "Epoch 99/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0960 - accuracy: 0.9649 - val_loss: 0.6017 - val_accuracy: 0.8940\n",
      "Epoch 100/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0912 - accuracy: 0.9649 - val_loss: 0.6153 - val_accuracy: 0.8954\n"
     ]
    }
   ],
   "source": [
    "def train_model():\n",
    "  \n",
    "  model = create_model()\n",
    "  model.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "  logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "  tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "  model.fit(x=x_train, \n",
    "            y=y_train, \n",
    "            epochs=100, \n",
    "            validation_data=(x_test, y_test), \n",
    "            callbacks=[tensorboard_callback])\n",
    "\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SxvXc4hoKW7d"
   },
   "source": [
    "Start TensorBoard within the notebook using [magics](https://ipython.readthedocs.io/en/stable/interactive/magics.html):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Po7rTfQswAMT"
   },
   "source": [
    "<!-- <img class=\"tfo-display-only-on-site\" src=\"https://github.com/tensorflow/tensorboard/blob/master/docs/images/notebook_tensorboard.png?raw=1\"/> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQq3UHgmLBpC"
   },
   "source": [
    "You can now view dashboards such as scalars, graphs, histograms, and others. Some dashboards are not available yet in Colab (such as the profile plugin).\n",
    "\n",
    "The `%tensorboard` magic has exactly the same format as the TensorBoard command line invocation, but with a `%`-sign in front of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NiIMwOG8MR_g"
   },
   "source": [
    "You can also start TensorBoard before training to monitor it in progress:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ALxC8BbWWV91"
   },
   "source": [
    "<!-- <img class=\"tfo-display-only-on-site\" src=\"https://github.com/tensorflow/tensorboard/blob/master/docs/images/notebook_tensorboard_two_runs.png?raw=1\"/> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GUSM8yLrO2yZ"
   },
   "source": [
    "The same TensorBoard backend is reused by issuing the same command. If a different logs directory was chosen, a new instance of TensorBoard would be opened. Ports are managed automatically. \n",
    "\n",
    "Start training a new model and watch TensorBoard update automatically every 30 seconds or refresh it with the button on the top right:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ixZlmtWhMyr4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "   1/1875 [..............................] - ETA: 0s - loss: 2.4365 - accuracy: 0.0312WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0019s vs `on_train_batch_end` time: 0.0214s). Check your callbacks.\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4999 - accuracy: 0.8216 - val_loss: 0.4045 - val_accuracy: 0.8547\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3839 - accuracy: 0.8613 - val_loss: 0.4074 - val_accuracy: 0.8540\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3512 - accuracy: 0.8718 - val_loss: 0.3742 - val_accuracy: 0.8632\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3294 - accuracy: 0.8788 - val_loss: 0.3473 - val_accuracy: 0.8713\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3164 - accuracy: 0.8834 - val_loss: 0.3441 - val_accuracy: 0.8746\n"
     ]
    }
   ],
   "source": [
    "train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IlDz2oXBgnZ9"
   },
   "source": [
    "You can use the `tensorboard.notebook` APIs for a bit more control:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ko9qeSQHLrEh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known TensorBoard instances:\n",
      "  - port 6006: logdir logs (started 0:00:22 ago; pid 948)\n"
     ]
    }
   ],
   "source": [
    "from tensorboard import notebook\n",
    "notebook.list() # View open TensorBoard instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hzm9DNVILxJe"
   },
   "outputs": [],
   "source": [
    "# Control TensorBoard display. If no port is provided, \n",
    "# the most recently launched TensorBoard is used\n",
    "notebook.display(port=6006, height=1000) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "za2GqzKiWY-R"
   },
   "source": [
    "<!-- <img class=\"tfo-display-only-on-site\" src=\"https://github.com/tensorflow/tensorboard/blob/master/docs/images/notebook_tensorboard_tall.png?raw=1\"/> -->"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "tensorboard_in_notebooks.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
